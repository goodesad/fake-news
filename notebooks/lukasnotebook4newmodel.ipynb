{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0807490",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "796056be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Embedding, Flatten, Masking, Dropout, LSTM, GRU\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer as wn\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.preprocessing import LabelEncoder as le\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bf46a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = '../raw_data'\n",
    "lyricsdf = pd.read_csv(os.path.join(csv_path, 'song_lyrics.csv'))\n",
    "recipesdf = pd.read_csv(os.path.join(csv_path, 'recipes.csv'))\n",
    "fooddf = pd.read_csv(os.path.join(csv_path, 'food_reviews.csv'))\n",
    "bookdf = pd.read_csv(os.path.join(csv_path, 'book_descriptions.csv'))\n",
    "cleanfake = pd.read_csv(os.path.join(csv_path, 'clean_data_Fake.csv'))\n",
    "cleantrue = pd.read_csv(os.path.join(csv_path, 'clean_data_True.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa8cdf63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       Artist                                  Title  \\\n",
       " 0      Khalid                     Young Dumb & Broke   \n",
       " 1      Khalid                               Location   \n",
       " 2      Khalid                                 Better   \n",
       " 3      Khalid                                   Talk   \n",
       " 4      Khalid                                  Saved   \n",
       " ...       ...                                    ...   \n",
       " 4163  Beyoncé  Check On It (Beyoncé Experience Live)   \n",
       " 4164  Beyoncé     Ring The Alarm (Tranzformas Remix)   \n",
       " 4165  Beyoncé                           Radio (Live)   \n",
       " 4166  Beyoncé     Ring The Alarm (Karmatronic Remix)   \n",
       " 4167  Beyoncé        Denial (Hold Up, Beyoncé, Poem)   \n",
       " \n",
       "                             Album    Year        Date  \\\n",
       " 0                   American Teen  2017.0  2017-03-03   \n",
       " 1                   American Teen  2016.0  2016-04-30   \n",
       " 2                         Suncity  2018.0  2018-09-14   \n",
       " 3                     Free Spirit  2019.0  2019-02-07   \n",
       " 4                   American Teen  2017.0  2017-01-13   \n",
       " ...                           ...     ...         ...   \n",
       " 4163  The Beyoncé Experience Live  2007.0  2007-11-16   \n",
       " 4164                          NaN     NaN         NaN   \n",
       " 4165           I Am... World Tour  2010.0  2010-11-26   \n",
       " 4166                          NaN     NaN         NaN   \n",
       " 4167                          NaN     NaN         NaN   \n",
       " \n",
       "                                                   Lyric  \n",
       " 0     so you're still thinking of me just like i kno...  \n",
       " 1     send me your location let's focus on communica...  \n",
       " 2     better nothing baby nothing feels better i'm n...  \n",
       " 3     can we just talk can we just talk talk about w...  \n",
       " 4     4   the hard part always seems to last forever...  \n",
       " ...                                                 ...  \n",
       " 4163  ooh boy you looking like you like what you see...  \n",
       " 4164  refrain ring the alarm i've been through this ...  \n",
       " 4165  you're the only one that papa allowed to hang ...  \n",
       " 4166  refrain ring the alarm i've been through this ...  \n",
       " 4167  i tried to change closed my mouth more tried t...  \n",
       " \n",
       " [4168 rows x 6 columns],\n",
       "                                                     full\n",
       " 0      pan seared steak   vegetable noodle soup garni...\n",
       " 1      spinach and tortellini soup this is so delicio...\n",
       " 2      spinach and shrimp miso soup this quick simple...\n",
       " 3      no leftover corn dip so easy and delicious; un...\n",
       " 4      sunday chicken rice bake warm and hearty casse...\n",
       " ...                                                  ...\n",
       " 27995  spinach salad with lemon spinach is so good fo...\n",
       " 27996  slow baked tomatoes with garlic and mint from ...\n",
       " 27997  pumpkin harvest muffins the apples add a littl...\n",
       " 27998  low fat blueberry muffins with yogurt these ar...\n",
       " 27999  homemade vegetable dip this is always made whe...\n",
       " \n",
       " [28000 rows x 1 columns],\n",
       "                                                     Text\n",
       " 0      Once I saw peanut butter and chocolate cereal,...\n",
       " 1      Great natural treat for my cat, whose health I...\n",
       " 2      Great treats! I tear each one into 10 small pi...\n",
       " 3      This is a fantastic snack food and oh so choco...\n",
       " 4      This product is excellent. My dad bought this ...\n",
       " ...                                                  ...\n",
       " 27995  Nothing on the website or on Amazon.com let us...\n",
       " 27996  All of these \"prostate\" helpers made me skepti...\n",
       " 27997  My dogs eat this product every day, and I rath...\n",
       " 27998  Great coffee flavor even when a dash of skim m...\n",
       " 27999  This is a really nummy and nutty bar with choc...\n",
       " \n",
       " [28000 rows x 1 columns],\n",
       "                                              description\n",
       " 0      In January 2004 Jeffery Masson began an experi...\n",
       " 1      This riveting biography from the American Bar ...\n",
       " 2      A step-by-step introduction to using SAS (R) s...\n",
       " 3      Did you know that the Cornish pasty was invent...\n",
       " 4      Interactions/Mosaic Silver Edition is a fully ...\n",
       " ...                                                  ...\n",
       " 27995  When we break free from the habits that limit ...\n",
       " 27996  The goal of this book is to present the charac...\n",
       " 27997  In his best-selling book, Save the Cat! (R) Go...\n",
       " 27998  Book Two in the Annihilate Me Series! You must...\n",
       " 27999  Strategy and reality collide in Peter Fey's gr...\n",
       " \n",
       " [28000 rows x 1 columns],\n",
       "                                                     text  target\n",
       " 0      donald trump send embarrass new year eve messa...       0\n",
       " 1      drink brag trump staffer start russian collusi...       0\n",
       " 2      sheriff david clarke become internet joke thre...       0\n",
       " 3      trump so ob even obama name cod website image ...       0\n",
       " 4      pope francis call donald trump christmas speec...       0\n",
       " ...                                                  ...     ...\n",
       " 23476  mcpain john mccain furious iran treat u sailor...       0\n",
       " 23477  justice yahoo settle e mail privacy class acti...       0\n",
       " 23478  sunnistan u ally safe zone plan take territori...       0\n",
       " 23479  blow million al jazeera america finally call q...       0\n",
       " 23480  u navy sailor hold iranian military – sign neo...       0\n",
       " \n",
       " [23481 rows x 2 columns],\n",
       "                                                     text  target\n",
       " 0      budget fight loom republican flip fiscal scrip...       0\n",
       " 1      military accept transgender recruit monday pen...       0\n",
       " 2      senior republican senator let mueller job wash...       0\n",
       " 3      fbi russia probe help australian diplomat tip ...       0\n",
       " 4      trump want postal service charge much amazon s...       0\n",
       " ...                                                  ...     ...\n",
       " 21412  fully commit nato back new approach afghanista...       0\n",
       " 21413  lexisnexis withdraw two product chinese market...       0\n",
       " 21414  minsk cultural hub become from authority minsk...       0\n",
       " 21415  vatican upbeat possibility pope francis visit ...       0\n",
       " 21416  indonesia buy billion worth russian jet jakart...       0\n",
       " \n",
       " [21417 rows x 2 columns])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyricsdf, recipesdf, fooddf, bookdf, cleanfake, cleantrue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220990af",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a67ec9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04224fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 15:21:04.538127: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-08-29 15:21:04.541346: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-29 15:21:04.543876: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-0UJ0SON8): /proc/driver/nvidia/version does not exist\n",
      "2022-08-29 15:21:04.562106: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "binacc = BinaryAccuracy()\n",
    "prec = Precision()\n",
    "rec = Recall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d313020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bd0c49",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5475d56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lematize (words):\n",
    "    for index, word in enumerate (words):\n",
    "        words[index] = wn().lemmatize(word, pos='v')\n",
    "    for index, word in enumerate (words):\n",
    "        words[index] = wn().lemmatize(word, pos='r')\n",
    "    for index, word in enumerate (words):\n",
    "        words[index] = wn().lemmatize(word, pos='a')\n",
    "    for index, word in enumerate (words):\n",
    "        words[index] = wn().lemmatize(word, pos='n')\n",
    "    for index, word in enumerate (words):\n",
    "        words[index] = wn().lemmatize(word, pos='s')\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f19c6235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(sentence):\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    sentence = ''.join(char for char in sentence if not char.isdigit())\n",
    "    \n",
    "    for punctuation in string.punctuation:\n",
    "        sentence = sentence.replace(punctuation, ' ') \n",
    "    \n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    sentence = word_tokenize (sentence)\n",
    "    final = []\n",
    "    for word in sentence:\n",
    "        if word in stop_words:\n",
    "            sentence.remove(word)\n",
    "        if len(word) >= 3:\n",
    "            final.append(word)\n",
    "            \n",
    "    lematize(final)\n",
    "            \n",
    "    return ' '.join(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62cb6297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(history, title):\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize=(15,10))\n",
    "    \n",
    "    ax1.plot(history.history['loss'])\n",
    "    ax1.plot(history.history['val_loss'])\n",
    "    ax1.set_title(f'{title} Loss')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylim(ymin=0, ymax=2)\n",
    "    ax1.legend(['Train', 'Validation'], loc='best')\n",
    "    ax1.grid(axis=\"x\",linewidth=0.5)\n",
    "    ax1.grid(axis=\"y\",linewidth=0.5)    \n",
    "    \n",
    "    ax2.plot(history.history['binary_accuracy'])\n",
    "    ax2.plot(history.history['val_binary_accuracy'])\n",
    "    ax2.set_title(f'{title} Accuracy')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylim(ymin=0, ymax=2)\n",
    "    ax2.legend(['Train', 'Validation'], loc='best')\n",
    "    ax2.grid(axis=\"x\",linewidth=0.5)\n",
    "    ax2.grid(axis=\"y\",linewidth=0.5)    \n",
    "\n",
    "    ax3.plot(history.history['precision'])\n",
    "    ax3.plot(history.history['val_precision'])\n",
    "    ax3.set_title(f'{title} Precision')\n",
    "    ax3.set_ylabel('Precision')\n",
    "    ax3.set_xlabel('Epoch')\n",
    "    ax3.set_ylim(ymin=0, ymax=2)\n",
    "    ax3.legend(['Train', 'Validation'], loc='best')\n",
    "    ax3.grid(axis=\"x\",linewidth=0.5)\n",
    "    ax3.grid(axis=\"y\",linewidth=0.5)    \n",
    "    \n",
    "    ax4.plot(history.history['recall'])\n",
    "    ax4.plot(history.history['val_recall'])\n",
    "    ax4.set_title(f'{title} Recall')\n",
    "    ax4.set_ylabel('Recall')\n",
    "    ax4.set_xlabel('Epoch')\n",
    "    ax4.set_ylim(ymin=0, ymax=2)\n",
    "    ax4.legend(['Train', 'Validation'], loc='best')\n",
    "    ax4.grid(axis=\"x\",linewidth=0.5)\n",
    "    ax4.grid(axis=\"y\",linewidth=0.5)  \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f893aea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model (model_name, neurons):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(\n",
    "        input_dim=(len(tokenizer.word_index))+1, # +1 for the 0 padding\n",
    "        input_length=300, # Max_sentence_length (optional, for model summary)\n",
    "        output_dim=100,\n",
    "        mask_zero=True, # Built-in masking layer :)\n",
    "    ))\n",
    "    if model_name == 'lstm':\n",
    "        model.add(LSTM((neurons*2), return_sequences=False))\n",
    "        model.add(Dense((neurons), activation='relu'))\n",
    "    if model_name == 'gru':\n",
    "        model.add(GRU((neurons*2), return_sequences=False))\n",
    "        model.add(Dense((neurons), activation='relu'))\n",
    "    if model_name == 'cnn':\n",
    "        model.add(Conv1D(neurons, kernel_size=5, activation='tanh'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense((neurons/2), activation='relu'))\n",
    "    #model.add(Dropout(rate=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d936f9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(learning_rate=0.0001), \n",
    "              metrics=[binacc, prec, rec]) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e80407",
   "metadata": {},
   "source": [
    "# Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e955a8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        once saw peanut butter and cereal please that ...\n",
       "1        great natural treat for cat whose health stron...\n",
       "2        great treat each into piece for week puggle th...\n",
       "3        this snack food and think this the taste cerea...\n",
       "4        this buy this regularly back during thoroughly...\n",
       "                               ...                        \n",
       "27995    nothing website amazon com let know these be n...\n",
       "27996    all these helper make but have dull ache all t...\n",
       "27997    eat this every day and rather other pack becau...\n",
       "27998    great coffee flavor even when dash milk strong...\n",
       "27999    this nummy and bar with goodness the granola b...\n",
       "Name: Text, Length: 28000, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_proc = fooddf['Text'].apply(preprocessing)\n",
    "food_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "385b31e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        jeffery masson begin be about year two chick t...\n",
       "1        this biography from american bar association v...\n",
       "2        introduction sa statistical software foundatio...\n",
       "3        do know that cornish pasty be tin miner from p...\n",
       "4        interaction mosaic silver edition fully integr...\n",
       "                               ...                        \n",
       "27995    when break free from habit that world open let...\n",
       "27996    the book present the and assumption behavioral...\n",
       "27997    best sell book save the go movie blake snyder ...\n",
       "27998    book two annihilate you read the volume before...\n",
       "27999    strategy and collide fey history carrier us or...\n",
       "Name: description, Length: 28000, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_proc = bookdf['description'].apply(preprocessing)\n",
    "book_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfd3c6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        pan sear steak vegetable noodle soup garnish w...\n",
       "1        spinach and soup this cold winter month serve ...\n",
       "2        spinach and miso soup this simple soup full an...\n",
       "3        corn dip and unlike anything you have once the...\n",
       "4        sunday chicken rice bake warm and casserole wi...\n",
       "                               ...                        \n",
       "27995    spinach salad with spinach good for and waistl...\n",
       "27996    slow bake tomato with and from home and websit...\n",
       "27997    pumpkin harvest muffin the add moisture nice f...\n",
       "27998    low fat blueberry muffin with these the muffin...\n",
       "27999    homemade vegetable dip this always make when p...\n",
       "Name: full, Length: 28000, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes_proc = recipesdf['full'].apply(preprocessing)\n",
    "recipes_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fd9d55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       think just you not you you moment this just du...\n",
       "1       send location let cause need the and through t...\n",
       "2       well nothing baby nothing feel well not drink ...\n",
       "3       can just can just talk about goin before get l...\n",
       "4       the part always seem forever sometimes that ar...\n",
       "                              ...                        \n",
       "4163    ooh boy you like you what see win you over che...\n",
       "4164    refrain ring the be this long but damn see ano...\n",
       "4165    you the one that allow out with door close and...\n",
       "4166    refrain ring the be this long but damn see ano...\n",
       "4167    close more soft pretty le awake fast for wear ...\n",
       "Name: Lyric, Length: 4168, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_proc = lyricsdf['Lyric'].apply(preprocessing)\n",
    "lyrics_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e35b9635",
   "metadata": {},
   "outputs": [],
   "source": [
    "notnewsdf = pd.DataFrame(pd.concat([book_proc.sample(13575), food_proc.sample(13575), recipes_proc.sample(13575), lyrics_proc], ignore_index=True), columns=['text'])\n",
    "notnewsdf = notnewsdf.sample(n=len(notnewsdf), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd27f9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roast butternut squash and pasta from light pe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the lie more minute hard noodle other that noo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>when rain face and whole world your offer you ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the novel twelve house from national bestselli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grape jelly barbecue sauce and sauce you chick...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44888</th>\n",
       "      <td>easy crock pot turkey leg turkey leg taste gre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44889</th>\n",
       "      <td>inside hot get something that can buy fight bi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44890</th>\n",
       "      <td>chicken and dumpling not this yet but for reci...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44891</th>\n",
       "      <td>planner paper kate publish purple sloth</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44892</th>\n",
       "      <td>who believe that world famous supermodel iris ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44893 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target\n",
       "0      roast butternut squash and pasta from light pe...       0\n",
       "1      the lie more minute hard noodle other that noo...       0\n",
       "2      when rain face and whole world your offer you ...       0\n",
       "3      the novel twelve house from national bestselli...       0\n",
       "4      grape jelly barbecue sauce and sauce you chick...       0\n",
       "...                                                  ...     ...\n",
       "44888  easy crock pot turkey leg turkey leg taste gre...       0\n",
       "44889  inside hot get something that can buy fight bi...       0\n",
       "44890  chicken and dumpling not this yet but for reci...       0\n",
       "44891            planner paper kate publish purple sloth       0\n",
       "44892  who believe that world famous supermodel iris ...       0\n",
       "\n",
       "[44893 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notnewsdf['target'] = 0\n",
    "notnewsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a87f3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsdf = pd.concat([cleanfake, cleantrue], ignore_index=True)\n",
    "newsdf = newsdf.sample(n=len(newsdf), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c9652dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>see politically incorrect sign dairy queen own...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sander could endorse clinton white house bid s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>house tax chairman propose tweak tax cut bill ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>two fantastic tweet perfectly show main differ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trump campaign california denounce protester r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44893</th>\n",
       "      <td>trump right cnn very fake news federal judge r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44894</th>\n",
       "      <td>germany merkel tell erdogan speed eu aid turke...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44895</th>\n",
       "      <td>senate reject immigration bill…trump call tota...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44896</th>\n",
       "      <td>must watch mark steyn call political violence ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44897</th>\n",
       "      <td>dem congressman display cop pig paint house fl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44898 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target\n",
       "0      see politically incorrect sign dairy queen own...       1\n",
       "1      sander could endorse clinton white house bid s...       1\n",
       "2      house tax chairman propose tweak tax cut bill ...       1\n",
       "3      two fantastic tweet perfectly show main differ...       1\n",
       "4      trump campaign california denounce protester r...       1\n",
       "...                                                  ...     ...\n",
       "44893  trump right cnn very fake news federal judge r...       1\n",
       "44894  germany merkel tell erdogan speed eu aid turke...       1\n",
       "44895  senate reject immigration bill…trump call tota...       1\n",
       "44896  must watch mark steyn call political violence ...       1\n",
       "44897  dem congressman display cop pig paint house fl...       1\n",
       "\n",
       "[44898 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsdf['target'] = 1\n",
    "newsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "17454a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldf = pd.concat([newsdf, notnewsdf], ignore_index=True)\n",
    "fulldf = fulldf.sample(n=len(fulldf), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2c9c398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>american torch hypocrite gop lawmaker use affo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>british government extend northern ireland tal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this title this may have imperfection such mis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>onion raspberry jalapeno chutney with zing enj...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>peet major dickinson much all drink whenever g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89786</th>\n",
       "      <td>word search puzzle jumbo edition fun and word ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89787</th>\n",
       "      <td>kellyanne conway trump gracious prosecute clin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89788</th>\n",
       "      <td>slow cook mexican shred beef this come from co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89789</th>\n",
       "      <td>tweet trump definitely regret send probably aw...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89790</th>\n",
       "      <td>naacp member arrest protest trump racist attor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89791 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target\n",
       "0      american torch hypocrite gop lawmaker use affo...       1\n",
       "1      british government extend northern ireland tal...       1\n",
       "2      this title this may have imperfection such mis...       0\n",
       "3      onion raspberry jalapeno chutney with zing enj...       0\n",
       "4      peet major dickinson much all drink whenever g...       0\n",
       "...                                                  ...     ...\n",
       "89786  word search puzzle jumbo edition fun and word ...       0\n",
       "89787  kellyanne conway trump gracious prosecute clin...       1\n",
       "89788  slow cook mexican shred beef this come from co...       0\n",
       "89789  tweet trump definitely regret send probably aw...       1\n",
       "89790  naacp member arrest protest trump racist attor...       1\n",
       "\n",
       "[89791 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55a588d",
   "metadata": {},
   "source": [
    "# Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "332713c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(fulldf['text'], fulldf['target'], test_size=0.25)\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_token = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_token = tokenizer.texts_to_sequences(X_test)\n",
    "X_train_token = pad_sequences(X_train_token, dtype='int32', padding='post', maxlen=300)\n",
    "X_test_token = pad_sequences(X_test_token, dtype='int32', padding='post', maxlen=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a72c5e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 300, 100)          12172100  \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 296, 12)           6012      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3552)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 21318     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,199,437\n",
      "Trainable params: 12,199,437\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "1579/1579 [==============================] - 48s 28ms/step - loss: 0.1003 - binary_accuracy: 0.9663 - precision: 0.9862 - recall: 0.9460 - val_loss: 0.0072 - val_binary_accuracy: 0.9984 - val_precision: 0.9988 - val_recall: 0.9980\n",
      "Epoch 2/30\n",
      "1579/1579 [==============================] - 40s 25ms/step - loss: 0.0038 - binary_accuracy: 0.9989 - precision: 0.9994 - recall: 0.9983 - val_loss: 0.0069 - val_binary_accuracy: 0.9988 - val_precision: 0.9980 - val_recall: 0.9995\n",
      "Epoch 3/30\n",
      "1579/1579 [==============================] - 44s 28ms/step - loss: 0.0027 - binary_accuracy: 0.9992 - precision: 0.9995 - recall: 0.9989 - val_loss: 0.0059 - val_binary_accuracy: 0.9991 - val_precision: 0.9989 - val_recall: 0.9993\n",
      "Epoch 4/30\n",
      "1579/1579 [==============================] - 39s 25ms/step - loss: 0.0024 - binary_accuracy: 0.9994 - precision: 0.9996 - recall: 0.9992 - val_loss: 0.0061 - val_binary_accuracy: 0.9990 - val_precision: 0.9989 - val_recall: 0.9992\n",
      "Epoch 5/30\n",
      "1579/1579 [==============================] - 40s 25ms/step - loss: 0.0021 - binary_accuracy: 0.9995 - precision: 0.9996 - recall: 0.9994 - val_loss: 0.0063 - val_binary_accuracy: 0.9992 - val_precision: 0.9989 - val_recall: 0.9994\n",
      "Epoch 6/30\n",
      "1579/1579 [==============================] - 42s 27ms/step - loss: 0.0022 - binary_accuracy: 0.9996 - precision: 0.9997 - recall: 0.9994 - val_loss: 0.0064 - val_binary_accuracy: 0.9991 - val_precision: 0.9989 - val_recall: 0.9993\n",
      "Epoch 7/30\n",
      "1579/1579 [==============================] - 41s 26ms/step - loss: 0.0020 - binary_accuracy: 0.9996 - precision: 0.9997 - recall: 0.9995 - val_loss: 0.0066 - val_binary_accuracy: 0.9990 - val_precision: 0.9989 - val_recall: 0.9992\n",
      "Epoch 8/30\n",
      "1579/1579 [==============================] - 40s 26ms/step - loss: 0.0019 - binary_accuracy: 0.9996 - precision: 0.9997 - recall: 0.9996 - val_loss: 0.0065 - val_binary_accuracy: 0.9991 - val_precision: 0.9989 - val_recall: 0.9993\n",
      "640/702 [==========================>...] - ETA: 0s - loss: 0.0037 - binary_accuracy: 0.9990 - precision: 0.9991 - recall: 0.9989"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = compile_model(initialize_model('cnn', 12))\n",
    "model.summary()\n",
    "history = model.fit(X_train_token, y_train, \n",
    "      epochs=30, \n",
    "      batch_size=32,\n",
    "      validation_split=0.25,\n",
    "      callbacks=[es],\n",
    "    verbose = 1, \n",
    "    use_multiprocessing=True\n",
    "      )\n",
    "model.evaluate(X_test_token, y_test, verbose=1)\n",
    "plot_loss_accuracy(history, 'cnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281b65e8",
   "metadata": {},
   "source": [
    "# Conclusion: we're good to go!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3d3e3c",
   "metadata": {},
   "source": [
    "# Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393cabd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../fake-news/models/notnewsfromnews.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346a764b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "241.825px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "56ae917af43f87a17804ed3ad2b98996c1dfc0e446e2bc35c92af1859ff39fe7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
